{"ast":null,"code":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.StopWordsTokenizer = undefined;\n\nvar _createClass = function () {\n  function defineProperties(target, props) {\n    for (var i = 0; i < props.length; i++) {\n      var descriptor = props[i];\n      descriptor.enumerable = descriptor.enumerable || false;\n      descriptor.configurable = true;\n      if (\"value\" in descriptor) descriptor.writable = true;\n      Object.defineProperty(target, descriptor.key, descriptor);\n    }\n  }\n\n  return function (Constructor, protoProps, staticProps) {\n    if (protoProps) defineProperties(Constructor.prototype, protoProps);\n    if (staticProps) defineProperties(Constructor, staticProps);\n    return Constructor;\n  };\n}();\n\nvar _StopWordsMap = require('../StopWordsMap');\n\nfunction _classCallCheck(instance, Constructor) {\n  if (!(instance instanceof Constructor)) {\n    throw new TypeError(\"Cannot call a class as a function\");\n  }\n}\n/**\n * Stop words are very common (e.g. \"a\", \"and\", \"the\") and are often not semantically meaningful in the context of a\n * search. This tokenizer removes stop words from a set of tokens before passing the remaining tokens along for\n * indexing or searching purposes.\n */\n\n\nvar StopWordsTokenizer = exports.StopWordsTokenizer = function () {\n  /**\n   * Constructor.\n   *\n   * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n   */\n  function StopWordsTokenizer(decoratedTokenizer) {\n    _classCallCheck(this, StopWordsTokenizer);\n\n    this._tokenizer = decoratedTokenizer;\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  _createClass(StopWordsTokenizer, [{\n    key: 'tokenize',\n    value: function tokenize(text) {\n      return this._tokenizer.tokenize(text).filter(function (token) {\n        return !_StopWordsMap.StopWordsMap[token];\n      });\n    }\n  }]);\n\n  return StopWordsTokenizer;\n}();\n\n;","map":null,"metadata":{},"sourceType":"script"}